#!/usr/bin/env python3
# Merge tool for multiple JSON files (generated by weather_jma.py)
# Soomin K. Dec.23,2018
# <F9> to run this python file in vim editor (need to set :nnoremap)
# Repo: https://github.com/soominkimu/csv2json

'''
'''
import csv
import json
import os
import sys
import calendar

from c2j_util import *

if not os.path.exists(PathName.csv) or  \
   not os.path.exists(PathName.json):
    handleFileNotFoundError(PathName.csv + ' or ' + PathName.json)

# List of downloaded CSV filenames (http://bit.ly/2Lh4qzF)
csv_file_list = []
################
try:
    csv_file_list = [f for f in os.listdir(PathName.csv) \
                     if os.path.isfile(PathName.csv + f) and not f.startswith('.')]
except FileNotFoundError:
    handleFileNotFoundError(PathName.csv)

csv_file_list.sort()

# Column names to be extracted
colName = [ \
    'Date', \
    'Max',     None, None, None, None, \
    'Min',     None, None, None, None, \
    'Avg',     None, None, \
    'Rain',    None, None, None, \
    'SolarT',  None, None, None, \
    'SolarE',  None, None,  \
    'Snow',    None, None, None, None, None, None, None, None, None, None, \
    'Wind',    None, None, \
    'Humid',   None, None, \
    'Cloud',   None, None, \
    'StatusD', None, None, \
    'StatusN', None, None]

# col_extract_list = [1,6,11,14,18,22,25,36,39,42,45,48]
col_extract_list = []  # automatically build the list of columns to be extracted
col_cnt_list     = []  # keep the count of valid data in each column
################## #
for cx in range(1, len(colName)):  # exclude the 'Date' column at the index 0
    if colName[cx] is not None:
        col_extract_list.append(cx)
        col_cnt_list.append(0)

#######################################################################
## Main Module
def JMAMain(csvName):
    # Metadata in the output JSON file
    fname  = (csvName.split('.'))[0].split('-')
    locDF  = fname[0]  # location Data from Filename
    yearDF = fname[1]  # year from Data Filename

    # slice for old data
    colExtList = col_extract_list if int(yearDF) > 1960 else col_extract_list[:4]

    def getColName(col):
        return colName[colExtList[col]]

    def getCsvPath():
        return PathName.csv + csvName

    def getFullPathOut(itemName, year=yearDF):
        return PathName.json + locDF    + '-' \
                             + itemName + '-' \
                             + year     + '.json'

    def isCompactFormat(itemName):
        return itemName == 'c'

    def filter0(v, cx):   ## nullify '0'
        if cx in [14, 25]:  # column: Rain, Snow
            return '' if v == '0' else v
        else:
            return v

    def isEmptyArray(arr):  ## check if the array is empty
        for v in arr:
            if v != '':
                return False
        return True

    def getCompactColNames():
        s = ''
        for c, cx in enumerate(colExtList):
            if c > 0:
                s += '|'
            s += colName[cx]
        return s

    ###### Data store per column
    colDataList = []      # two-dimensional array
    for c in range(len(colExtList)):
        colDataList.append([])

    ###### Data store per date
    rowDataList = []      # two-dimmensional array (per year)
    yearsList = []
    date_from = ''
    date_to   = ''

    def WriteListJson(itemName, dataList, year=yearDF):
        fnJson = getFullPathOut(itemName, year)
        # Create a temp file to remove all the quotation characters in the JSON file
        ''' Unwanted quotation marks added when json.dump was called.
        Since I couldn't find easy way to prevent this behavior added a post process after dumping.
        Dump a temporary Json file and then apply some filters.  '''
        fnTemp = fnJson + '.temp'
        try:
            with open(fnTemp, 'w') as tf:
                json.dump(dataList, tf, ensure_ascii=False, separators=(',', ':'))
            with open(fnTemp, 'r') as tf:
                outData = tf.readline().replace('"', '')
        except FileNotFoundError:
            handleFileNotFoundError(fnTemp)

        meta = '{"meta":{"location":"' + locDF   \
                     + '","from":"' + date_from  \
                     + '","to":"'   + date_to    \
                     + '","item":"' + (getCompactColNames() if isCompactFormat(itemName) else itemName) \
                     + '"},\n'

        try:
            # Output the JSON file with the meta data
            with open(fnJson, 'w') as jf:
                jf.write(meta)
                jf.write('"data":')
                jf.write(outData)
                jf.write('}')
        except FileNotFoundError:
            handleFileNotFoundError(fnJson)

        # Cleanup
        if os.path.exists(fnTemp):
            os.remove(fnTemp)
        else:
            print(fnTemp, ' - File not exist')

        szJson = os.path.getsize(fnJson)    # ternary operator
        print(Deco.rowIcon if isCompactFormat(itemName) else Deco.colIcon, \
              fnJson, ' (', getFSize(szJson), ') ', end='')
        if isCompactFormat(itemName):
            daysInYear = 366 if calendar.isleap(int(year)) else 365
            print(len(dataList), 'days ', \
                  Deco.LeapYear if (daysInYear == 366) else Deco.NoLeap,  \
                  Deco.warning + 'Incomplete data!' if (len(dataList) != daysInYear) else '')
        else:
            print(Deco.tabs, getYears(len(dataList)))
        return szJson

    # Read CSV file
    print(Deco.csvIcon, ' Data Source:', getCsvPath())
    daysJson = 0
    try:
        with open(getCsvPath(), 'r', encoding='utf-8') as cf:
            inData = csv.reader(cf, delimiter=',')
            ''' Process CSV data
            1. Save to colDataList[c] per column (i.e. per item) for each daily data
            2. Save to rowDataList[y] every column per day combining to a compact form, per year list '''
            yrId = -1  # index for the yearly list
            for row in inData:
                if ('/' not in row[0]) or (not row[0][:4].isnumeric()):   # skip header part (that has no date)
                    continue
                s = ''
                date_to = row[0][:10]  # to save out of the loop, ex: 2018/12/20
                for c, cx in enumerate(colExtList):
                    if row[cx] != '':
                        col_cnt_list[c] += 1
                    val = filter0(row[cx], cx)
                    colDataList[c].append(val)
                    if c > 0:
                        s += '|'             # compact form delimiter
                    if val is not '':
                        s += row[cx]
                if (daysJson == 0) or (row[0].endswith('/1/1')):  # start date of the year
                    if (daysJson == 0):
                        date_from = date_to
                    rowDataList.append([])   # initialize new rowData for the new year
                    yearsList.append(date_to[:4])
                    yrId  += 1
                    print(Deco.yearIcon, yearsList[len(yearsList)-1], end='')  # print out the year
                rowDataList[yrId].append(s)
                daysJson += 1
    except UnicodeDecodeError:
        handleCriticalError('UnicodeDecodeError')
    print('->Total', daysJson, 'days (', getYears(daysJson), ')')

    szColJson = 0
    szRowJson = 0
    for col in range(len(colExtList)):
        if col_cnt_list[col] > 0:
            szColJson += WriteListJson(getColName(col), colDataList[col])
    print(Deco.sizeHeadC, getFSize(szColJson), ' in total.')

    for y in range(len(yearsList)):
        szRowJson += WriteListJson('c', rowDataList[y], yearsList[y])  #'c' for compact format
    print(Deco.sizeHeadR, getFSize(szRowJson), ' in total. ', Deco.success)

    return szColJson, szRowJson, daysJson   # construct a tuple

#######################################################################
print(Deco.startIcon, 'TMA Data - Column IDs to be extracted:', col_extract_list, '(', len(colName), 'columns)')
szColTotal = 0
szRowTotal = 0
daysTotal  = 0
for fn in csv_file_list:
    szC, szR, d = JMAMain(fn)
    szColTotal += szC
    szRowTotal += szR
    daysTotal  += d
## REPORT statistics
print(Deco.totalHead, 'Column-wise   data:', getFSize(szColTotal), 'in total.')
print(Deco.totalHead, 'Daily compact data:', getFSize(szRowTotal), 'in total.', \
      round(szRowTotal/daysTotal, 1), 'bytes/day (', \
      getFSize(szRowTotal/(daysTotal/365.25)), '/year) in average.')
print(Deco.totalHead, daysTotal, ' days (', getYears(daysTotal), ') in total.')

## End of program
